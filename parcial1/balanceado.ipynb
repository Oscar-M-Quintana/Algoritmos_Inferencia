{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento promedio (validación cruzada): 0.6248875155851901\n",
      "Evaluación con umbral = 0.48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.61      0.60       466\n",
      "           1       0.59      0.58      0.59       454\n",
      "\n",
      "    accuracy                           0.59       920\n",
      "   macro avg       0.59      0.59      0.59       920\n",
      "weighted avg       0.59      0.59      0.59       920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importar librerías al principio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Función para cargar y balancear el dataset\n",
    "def cargar_balancear_dataset(ruta_csv):\n",
    "    df = pd.read_csv(ruta_csv)\n",
    "    class_0 = df[df['not.fully.paid'] == 0]\n",
    "    class_1 = df[df['not.fully.paid'] == 1]\n",
    "    class_0_balanced = class_0.sample(len(class_1), random_state=42)\n",
    "    df_balanced = pd.concat([class_0_balanced, class_1])\n",
    "    X = df_balanced.drop('not.fully.paid', axis=1)\n",
    "    y = df_balanced['not.fully.paid']\n",
    "    return X, y\n",
    "\n",
    "# Función para preprocesar los datos (One-Hot Encoding, estandarización y PCA)\n",
    "def preprocesar_datos(X_train, X_test):\n",
    "    # Hacer One-Hot Encoding de todo el conjunto de datos (entrenamiento + prueba) para mantener las mismas columnas\n",
    "    X_combined = pd.concat([X_train, X_test], axis=0)\n",
    "    X_combined_encoded = pd.get_dummies(X_combined, drop_first=True)\n",
    "\n",
    "    # Separar de nuevo el conjunto de entrenamiento y prueba después del One-Hot Encoding\n",
    "    X_train_encoded = X_combined_encoded.iloc[:len(X_train), :]\n",
    "    X_test_encoded = X_combined_encoded.iloc[len(X_train):, :]\n",
    "\n",
    "    # Estandarizar las características\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
    "    X_test_scaled = scaler.transform(X_test_encoded)\n",
    "\n",
    "    # Aplicar PCA\n",
    "    pca = PCA(n_components=10)\n",
    "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "    X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "    return X_train_pca, X_test_pca, scaler, pca\n",
    "\n",
    "# Función para entrenar y validar el modelo LDA\n",
    "def entrenar_modelo(X_train, y_train):\n",
    "    lda_model = LinearDiscriminantAnalysis()\n",
    "    cross_val_scores = cross_val_score(lda_model, X_train, y_train, cv=5)\n",
    "    lda_model.fit(X_train, y_train)\n",
    "    print(f\"Rendimiento promedio (validación cruzada): {cross_val_scores.mean()}\")\n",
    "    return lda_model\n",
    "\n",
    "# Función para evaluar el modelo con ajuste de umbral\n",
    "def evaluar_con_umbral(modelo, X_test, y_test, umbral=0.5):\n",
    "    y_probs = modelo.predict_proba(X_test)[:, 1]\n",
    "    y_pred_threshold = np.where(y_probs > umbral, 1, 0)\n",
    "    print(f\"Evaluación con umbral = {umbral}\")\n",
    "    print(classification_report(y_test, y_pred_threshold))\n",
    "\n",
    "\n",
    "# Ejecución del código\n",
    "\n",
    "# Cargar y balancear el dataset\n",
    "X, y = cargar_balancear_dataset('./Clasificacion_banco.csv')\n",
    "\n",
    "# Dividir el dataset en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Preprocesar los datos con la nueva función\n",
    "X_train_pca, X_test_pca, scaler, pca = preprocesar_datos(X_train, X_test)\n",
    "\n",
    "# Entrenar el modelo\n",
    "lda_model = entrenar_modelo(X_train_pca, y_train)\n",
    "\n",
    "# Evaluar el modelo con un umbral ajustado\n",
    "evaluar_con_umbral(lda_model, X_test_pca, y_test, umbral=0.48)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de clasificación para el dataset completo:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.67      0.64      1533\n",
      "           1       0.63      0.57      0.60      1533\n",
      "\n",
      "    accuracy                           0.62      3066\n",
      "   macro avg       0.62      0.62      0.62      3066\n",
      "weighted avg       0.62      0.62      0.62      3066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocesar el dataset completo (X)\n",
    "def preprocesar_completo(X, scaler, pca):\n",
    "    # Hacer One-Hot Encoding del dataset completo\n",
    "    X_encoded = pd.get_dummies(X, drop_first=True)\n",
    "    \n",
    "    # Estandarizar usando el scaler entrenado\n",
    "    X_scaled = scaler.transform(X_encoded)\n",
    "    \n",
    "    # Aplicar PCA usando el modelo PCA entrenado\n",
    "    X_pca = pca.transform(X_scaled)\n",
    "    \n",
    "    return X_pca\n",
    "\n",
    "# Aplicar el preprocesamiento al dataset completo\n",
    "X_completo_pca = preprocesar_completo(X, scaler, pca)\n",
    "\n",
    "# Hacer predicciones con el modelo entrenado en el dataset completo\n",
    "y_pred_completo = lda_model.predict(X_completo_pca)\n",
    "\n",
    "# Evaluar el rendimiento del modelo en el dataset completo\n",
    "print(\"Reporte de clasificación para el dataset completo:\")\n",
    "print(classification_report(y, y_pred_completo))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
